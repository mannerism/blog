---
layout: post
title: "오디어 데이터에 관하여"
date: 2022-09-27 4:48:49 +0900
categories: study
---

간만에 너무 좋은 글을 읽어서 한국어로 번역 + 공부하기 위해서 이 시리즈를 시작해 볼까 한다. [원문 링크](https://huggingface.co/learn/audio-course/chapter1/audio_data)

## 오디오 데이터에 대한 소개

원래 소리는 끊김없이 쭉 뻗어나가는 시그널이다, 무슨 말이냐면 정해진 시간 안에 무한한 수의 시그널 값이 존재한다는 뜻이다. 문제는 이 자연에서 발생하는 소리를 디지털로 전환할 때 발생한다. 소리를 프로세싱 하고 저장하고 디지털 기기에서 재생하기 위해서는 이 끊임없이 이어지는 소리 파장을 정해진 값으로 표현할 수 있어야 하는데 이를 우린 '소리의 디지털화'라고 한다.

오디오 데이터셋을 보면 나레이션이나 음악같은 소리가 포함된 디지털 파일을 볼 수 있다. .wav (Waveform Audio File)이나 .flac(Free Lossless Audio Codec)이나 .mp3(MPEG-1 Audio Layer 3) 확장자를 가진 파일들이 그런것들이다. 이 포맷은 각자 다른 방식으로 오디오 시그널을 디지털화 한다.

그럼 이제 어떻게 오디오 시그널이 디지털화 되는지 알아보자. 아날로그 시그널은 처음 마이크를 통해 캡쳐된다. 그리고 나서 소리 웨이브를 전기 시그널로 변환한다. 이 전기 시그널은 다시 'Analog-to-Digial 변환기'를 통해 디지털화되는데 이를 우린 '샘플링'이라고 한다.

## 샘플링과 샘플링 속도

샘플링이란 정해진 주기로 오디오 시그널을 측정하는 것이다. 샘플링 된 파형은 - 소리의 모양 waveform - 특정 값으로 정해져 있다, 왜냐면 딱 정해진 주기로 측정을 했기 때문에 이 시간에 이 값 이렇게 떨어진다.

![waveform-sampling](https://upload.wikimedia.org/wikipedia/commons/c/c3/Signal_Sampling.svg)

위키피디아 이미지 Sampling (signal processing)

샘플링 속도 또는 샘플링 주파수는 초당 몇번 샘플링 하는지를 의미한다. 주로 hertz(Hz)로 측정된다. 예를 좀 들어보자면 CD 음질의 오디오의 샘플링 속도는 44,100Hz인데 이는 약 초당 44,100번 샘플 값을 측정했다는 의미다. 비교를 하자면 고음질 오디오의 샘플링 속도는 192,000 Hz 또는 192kHz이다. 통상적으로 AI 스피치 모델을 훈련시키는데 사용하는 샘플링 속도는 16,000 Hz 또는 16kHz이다.

어떤 샘플링 속도를 쓰냐에 따라 특정 오디오 시그널에서 캡쳐할 수 있는 가장 높은 주파수가 변한다. 이걸 우린 Nyquist Limit이라고도 하는데 주로 샘플링 속도의 반이다. 인간이 들을 수 있는 인간의 스피치의 주파수는 8kHz 이하 이기 때문에 인간의 스피치를 샘플링하는데에 16kHz면 충분하다. 더 높은 샘플링 속도를 사용해 봐야 더 많은 정보를 캡쳐할 수 없고 컴퓨팅 파워만 더 쓰게 된다. 만약 더 낮은 속도로 샘플링을 진행한다면 정보의 누락이 있다. 인간의 목소리를 8kHz로 샘플링 한다면 먹먹하게 들린다 왜냐면 더 높은 주파수의 소리를 캡쳐하지 못하게 때문이다.

오디오 데이터셋 안에 있는 오디오 파일로 작업을 할 때 관건은 오디오 파일 모두 동일한 샘플링 속도를 가지고 있어야 한다. 만약 당신이 커스텀 오디오 데이터를 가지고 pre-trained model을 fine-tuning한다고 가정했을 떄 당신이 사용하는 커스텀 오디오 데이터는 AI 모델이 pre-trained 된 데이터의 샘플링 속도와 동일해야 한다는 것이다. 샘플링 속도는 AI모델에 피드 되는 오디오 샘플들의 시간 간격을 결정하는데 이는 결국 특정 오디오 데이터의 해상도(temporal resolution)를 결정짓는다.한 가지 예를 들어보자. 5초 짜리 소리가 16,000Hz로 샘플링 되면 80,000개의 값이 나온다. 만약 동일한 사운드를 8,000Hz로 샘플링 하면 40,000개의값이 나온다. 오디오 작업에 수행되는 Transformer 오디오 데이터를 순차적으로 처리하고 Attention Mechanisms을 사용해 오디오를 배운다. 다른 샘플링 속도로 샘플된 오디오는 다른 수의 값을 가지고 있기 때문에 인공지능 모델이 이를 처리하기 매우 어려워 진다. 그래서 우리는 preprocessing으로 이 샙플링 속도를 맞춰주는데 이른 우린 리샘플링 이라고 한다.

## Amplitude와 Bit Depth

샘플링 속도가 얼마나 자주 샘플을 측정하느냐 였다면 매번 측정되는 값은 뭘까?

소리는 인간이 들을 수 있는 주파수 내에서 발생하는 공기 압력의 변화이다. 소리의 Amplitude은 특정 시간에 포착된 소리의 압력 수치를 뜻하며 이를 우린 데시벨 dB로 측정한다. 우리는 이 Amplitude를 소리의 크기로 느낀다. 한 가지 예로, 인간의 보통 대화 소리는 60dB이하고 락 콘서트장 소리는 약 125 dB이며 인간이 들을 수 있는 최대의 소리에 근접하다.

디지털 오디오에서 각 오디오 샘플은 시간 상에서 오디오 파형의 진폭을 기록합니다. 샘플의 비트 깊이는 이 진폭 값을 얼마나 정밀하게 기술할 수 있는지를 결정한다. 비트 깊이가 높을수록 디지털 표현이 원래의 연속적인 소리 파형을 더 정확하게 근사화한다.

16비트와 24비트는 가장 흔한 오디오 비트 깊이이다. 각각은 연속적인 값이 이산적인 값으로 변환될 때 진폭 값이 양자화될 수 있는 가능한 단계의 수를 나타내는 이진 용어이다. 16비트 오디오의 경우 65,536 단계, 24비트 오디오의 경우 놀랄 만한 16,777,216 단계가 된다. 양자화는 연속적인 값을 이산적인 값으로 반올림하는 과정이므로 샘플링 과정에서 소음이 도입된다. 비트 깊이가 높을수록 이 양자화 소음이 작아진다. 실제로 16비트 오디오의 양자화 소음은 이미 듣기에 무해할 정도로 작아서 일반적으로 더 높은 비트 깊이를 사용하는 것이 필요하지 않다.

32비트 오디오도 종종 만날 수 있는데 이는 샘플을 부호화된 정수가 아닌 부동 소수점 값으로 저장한다. 32비트 부동 소수점 값의 정밀도는 24비트로, 이는 24비트 오디오의 비트 깊이와 동일하다. 부동 소수점 오디오 샘플은 일반적으로 [-1.0, 1.0] 범위 내에 있어야 한다. 기계 학습 모델이 부동 소수점 데이터에서 자연스럽게 작동하기 때문에 오디오는 모델 교육에 사용되기 전에 먼저 부동 소수점 형식으로 변환되어야 한다. 이에 대한 처리 방법은 다음 섹션인 전처리에서 살펴볼 것이다.

디지털 오디오의 진폭은 연속적인 오디오 신호와 마찬가지로 일반적으로 데시벨(dB)로 표현된다. 인간 청각은 로그스케일이기 때문에 — 우리의 귀는 큰 소리보다는 작은 소리의 작은 변동에 민감하다 — 소리의 음량은 데시벨로 표시되면 해석하기가 더 쉽다. 현실 세계의 오디오 데시벨 스케일은 0 dB에서 시작하여 이는 인간이 들을 수 있는 가장 조용한 소리를 나타내며, 더 큰 값은 더 큰 소리를 나타낸다. 그러나 디지털 오디오 신호의 경우 0 dB가 가능한 가장 큰 진폭을 나타내며, 다른 모든 진폭은 음수이다. 간단한 규칙으로 말하자면: 매 -6 dB마다 진폭이 절반으로 감소하며, -60 dB 아래의 값은 볼륨을 정말로 높이지 않는 한 일반적으로 들을 수 없다.
